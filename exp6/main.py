import torchvision
import time


# ç½‘ç»œæ¨¡å‹
def timeShow(fn):
    def _wrapper(*args, **kwargs):
        start = time.time()
        ans = fn(*args, **kwargs)
        print("%s cost %s second" % (fn.__name__, time.time() - start))
        return ans

    return _wrapper


from torchvision import datasets, transforms

imageTransform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
testTransform = transforms.Compose([

    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
import torch

# ç„å­¦åŠ é€Ÿ
torch.backends.cudnn.benchmark = True
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

import torch.nn as nn

criterion = nn.CrossEntropyLoss()
from torch.autograd import Variable


def train():
    global epoch

    model.train()

    @timeShow
    def perEpoch(epoch):
        print(f"epoch{epoch}")
        showPercent = round(len(train_loader))
        for batch_idx, (data, target) in enumerate(train_loader):
            # gpuåŠ é€Ÿ
            data, target = data.cuda(), target.cuda()

            optimizer.zero_grad()
            # å‰å‘ä¼ æ’­
            output = model(data)
            # è®¡ç®—æŸå¤±å‡½æ•°
            loss = criterion(output, target)
            # åå‘ä¼ æ’­
            loss.backward()
            scheduler.step(loss)
            # è°ƒå‚
            optimizer.step()
            if batch_idx % showPercent == 0:
                print(f'{epoch} {batch_idx}/{len(train_loader)} {loss.item()}  ')
        # torch.save(model, f'./model/resnet50{epoch}')
        # torch.save(model, f'./model/resnet50Newest')
        print("start save")
        torch.save({"model": model, "optimizer": optimizer.state_dict(), "epoch": epoch}, f'./model/{NetTitle}Newest')
        print("save success")

    # è·‘néè®­ç»ƒé›†
    for i in range(1):
        perEpoch(epoch)
        epoch += 1


import math


def test():
    def dotest(title, loader):
        with torch.no_grad():
            model.eval()  # è®¾ç½®ä¸ºtestæ¨¡å¼
            correct = 0  # åˆå§‹åŒ–é¢„æµ‹æ­£ç¡®çš„æ•°æ®ä¸ªæ•°ä¸º0
            total = len(loader)
            # æ‰“logçš„æ¦‚ç‡
            showPercent = round(total)
            totalImg = 0
            for index, (data, target) in enumerate(loader):
                data, target = data.cuda(), target.cuda()
                data, target = Variable(data), Variable(target)
                output = model(data)
                _, predicted = torch.max(output.data, 1)
                correct += (predicted == target).sum().item()
                totalImg += target.size(0)
                if index % showPercent == 0:
                    print(f"{title}è¿›åº¦ {math.floor(index / total * 100)}%")
            print(f"{title}æ­£ç¡®ç‡ {correct}/{totalImg} = {round(correct / totalImg * 100)}%")
            return correct / totalImg

    rate1 = dotest("æµ‹è¯•é›†", test_loader)
    # rate2 = dotest("è®­ç»ƒé›†", test_train_loader)
    rate2 = 0
    return rate1, rate2


if __name__ == "__main__":
    import resnet18

    # å¸¦é¢„è®­ç»ƒçš„åˆå§‹æ¨¡å‹
    # modelNetTorch = torchvision.models.resnet18(pretrained=True)
    modelNetTorch = resnet18.ResNet18()
    try:

        modelNetTorch.classifier = nn.Linear(modelNetTorch.classifier.in_features, 10)
    except:
        modelNetTorch.fc = nn.Linear(modelNetTorch.fc.in_features, 10)

    modelNet = modelNetTorch
    # å­˜æ¡£åå­—
    NetTitle = "ResNet18"
    # çˆ†æ˜¾å­˜äº†å°±ç¼©ä¸€ç¼©
    train_batch_size = 256
    test_batch_size = 256
    lr = 0.001
    testrate = 0

    #è®­ç»ƒæ•°æ®
    trainDataset = datasets.CIFAR10('./train', train=True, download=True, transform=imageTransform)
    train_loader = torch.utils.data.DataLoader(trainDataset, batch_size=train_batch_size, pin_memory=True, shuffle=True,
                                               num_workers=2)
    #æµ‹è¯•æ•°æ®
    testDataset = datasets.CIFAR10('./train', train=False, download=True, transform=testTransform)
    test_loader = torch.utils.data.DataLoader(testDataset, batch_size=test_batch_size,num_workers=2)
    #è®­ç»ƒé›†æµ‹è¯•
    # testTrainDataset = datasets.CIFAR10('./train', train=True, download=True, transform=testTransform)
    # test_train_loader = torch.utils.data.DataLoader(testTrainDataset, batch_size=test_batch_size,num_workers=2)


    def changegrad(net):
        try:
            fclayer=net.classifier
        except:
            fclayer = net.fc

        ignored_params = list(map(id, fclayer.parameters()))
        base_params = filter(lambda p: id(p) not in ignored_params, net.parameters())
        # å¯¹ä¸åŒå‚æ•°è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡
        params_list = [{'params': base_params, 'lr': 0.001}, ]
        params_list.append({'params': fclayer.parameters(), 'lr': 0.01})
        for k, v in net.named_parameters():
            v.requires_grad = True
        return params_list


    try:

        save = torch.load(f'./model/{NetTitle}Newest')
        # save = torch.load(f'./model/{NetTitle}Best')
        model = save["model"]
        params_list = changegrad(model)
        model.cuda()
        optimizer = torch.optim.Adam(params_list, lr=lr,
                                     weight_decay=0.00008)
        try:
            optimizer.load_state_dict(save["optimizer"])
        except:
            pass
        epoch = save["epoch"]
        print(f"load from './model/{NetTitle}Newest'")
    except:
        # å…¨æ–°è®­ç»ƒ
        params_list = changegrad(modelNet)
        model = modelNet.cuda()
        optimizer = torch.optim.Adam(params_list, lr=lr,
                                     weight_decay=0.00008)
        epoch = 0

    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.99,
                                                           patience=2 * len(train_loader), verbose=True,
                                                           threshold=0.0001, threshold_mode='rel', cooldown=1,
                                                           min_lr=0.0001, eps=1e-08)

    rate1, rate2 = test()
    testCorrectMax = rate1
    while rate1 < 0.9 or rate2 < 0.95:
        # ç»™ğŸ‘´è®­ç»ƒåˆ°åˆæ ¼ä¸ºæ­¢

        train()
        rate1, rate2 = test()

        if rate1 > testCorrectMax:
            testCorrectMax = rate1
            print("æ–°çš„æ­£ç¡®ç‡")
            torch.save({"model": model, "optimizer": optimizer.state_dict(), "epoch": epoch},
                       f'./model/{NetTitle}Best')

    pass
